{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify participants with inconsistent responses\n",
    "def identify_inconsistent_participants(df):\n",
    "    \"\"\"\n",
    "    Identify participants with inconsistent responses:\n",
    "    - Choose City B but estimate P(City A > City B) < 50%\n",
    "    - Choose City A but estimate P(City A > City B) > 50%\n",
    "    \n",
    "    Returns: DataFrame with inconsistent participants and their details\n",
    "    \"\"\"\n",
    "    inconsistent_participants = []\n",
    "    \n",
    "    # Get prediction task data only\n",
    "    pred_data = df[df['trial_type'] == 'prediction-task'].copy()\n",
    "    \n",
    "    for participant_id in pred_data['participant_id'].unique():\n",
    "        participant_rows = pred_data[pred_data['participant_id'] == participant_id]\n",
    "        \n",
    "        for _, row in participant_rows.iterrows():\n",
    "            prob_est = row.get('probability_estimate')\n",
    "            travel_choice = row.get('travel_choice')\n",
    "            phase = row.get('phase', 'unknown')\n",
    "            condition = row.get('condition_name', 'unknown')\n",
    "            \n",
    "            if pd.notna(prob_est) and pd.notna(travel_choice) and travel_choice in ['City A', 'City B']:\n",
    "                # Check for inconsistency\n",
    "                is_inconsistent = False\n",
    "                inconsistency_type = None\n",
    "                \n",
    "                if travel_choice == 'City B' and prob_est < 50:\n",
    "                    # Participant chooses City B but thinks City A has lower probability\n",
    "                    is_inconsistent = True\n",
    "                    inconsistency_type = 'chose_city_b_but_low_prob_cityA'\n",
    "                elif travel_choice == 'City A' and prob_est > 50:\n",
    "                    # Participant chooses City A but thinks City A has higher probability  \n",
    "                    is_inconsistent = True\n",
    "                    inconsistency_type = 'chose_city_a_but_high_prob_cityA'\n",
    "                \n",
    "                if is_inconsistent:\n",
    "                    inconsistent_participants.append({\n",
    "                        'participant_id': participant_id,\n",
    "                        'phase': phase,\n",
    "                        'condition': condition,\n",
    "                        'travel_choice': travel_choice,\n",
    "                        'probability_estimate': prob_est,\n",
    "                        'inconsistency_type': inconsistency_type\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(inconsistent_participants)\n",
    "\n",
    "def filter_consistent_participants(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Filter out participants with inconsistent responses\n",
    "    \n",
    "    Args:\n",
    "        df: Original dataframe\n",
    "        verbose: Print filtering details\n",
    "        \n",
    "    Returns:\n",
    "        Filtered dataframe with consistent participants only\n",
    "    \"\"\"\n",
    "    # Identify inconsistent participants\n",
    "    inconsistent_df = identify_inconsistent_participants(df)\n",
    "    \n",
    "    if len(inconsistent_df) > 0:\n",
    "        inconsistent_participant_ids = inconsistent_df['participant_id'].unique()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Found {len(inconsistent_participant_ids)} participants with inconsistent responses:\")\n",
    "            for participant_id in inconsistent_participant_ids:\n",
    "                participant_issues = inconsistent_df[inconsistent_df['participant_id'] == participant_id]\n",
    "                print(f\"  {participant_id}:\")\n",
    "                for _, issue in participant_issues.iterrows():\n",
    "                    print(f\"    Phase {issue['phase']}: chose {issue['travel_choice']} but estimated P(City A > City B) = {issue['probability_estimate']}%\")\n",
    "        \n",
    "        # Filter out inconsistent participants\n",
    "        filtered_df = df[~df['participant_id'].isin(inconsistent_participant_ids)].copy()\n",
    "        \n",
    "        if verbose:\n",
    "            original_participants = df['participant_id'].nunique()\n",
    "            filtered_participants = filtered_df['participant_id'].nunique()\n",
    "            print(f\"\\nFiltering results:\")\n",
    "            print(f\"  Original participants: {original_participants}\")\n",
    "            print(f\"  Inconsistent participants removed: {len(inconsistent_participant_ids)}\")\n",
    "            print(f\"  Remaining participants: {filtered_participants}\")\n",
    "        \n",
    "        return filtered_df, inconsistent_df\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"No inconsistent participants found.\")\n",
    "        return df, pd.DataFrame()\n",
    "\n",
    "print(\"Consistency checking functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humidity Prediction Study Analysis\n",
    "\n",
    "This notebook analyzes experimental data from the trust and uncertainty visualization study.\n",
    "The study examines how different visualization conditions affect user trust, confidence, and decision-making across two phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Circle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"Set2\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files from the data directory\n",
    "data_dir = Path('./data')\n",
    "csv_files = list(data_dir.glob('user_*.csv'))\n",
    "print(f\"Found {len(csv_files)} participant data files:\")\n",
    "for file in csv_files:\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and clean individual participant data\n",
    "def load_participant_data(file_path):\n",
    "    \"\"\"Load a single participant CSV file and clean the data\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Extract participant ID from filename if not in data\n",
    "        if 'participant_id' not in df.columns or df['participant_id'].isna().all():\n",
    "            participant_id = file_path.stem.split('_')[1]  # Extract from filename\n",
    "            df['participant_id'] = participant_id\n",
    "        \n",
    "        # Clean condition IDs and names\n",
    "        if 'condition_id' in df.columns:\n",
    "            df['condition_id'] = df['condition_id'].fillna('unknown')\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load all participant data\n",
    "all_data = []\n",
    "for file_path in csv_files:\n",
    "    participant_data = load_participant_data(file_path)\n",
    "    if participant_data is not None:\n",
    "        all_data.append(participant_data)\n",
    "        print(f\"Loaded data for participant: {participant_data['participant_id'].iloc[0] if not participant_data['participant_id'].isna().all() else 'unknown'}\")\n",
    "\n",
    "# Combine all participant data\n",
    "if all_data:\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nCombined dataset shape (before filtering): {combined_data.shape}\")\n",
    "    \n",
    "    # Filter out test participants\n",
    "    test_participants = ['test', 'Test', 'TEST']\n",
    "    before_count = combined_data['participant_id'].nunique()\n",
    "    combined_data = combined_data[~combined_data['participant_id'].isin(test_participants)]\n",
    "    combined_data = combined_data[combined_data['participant_id'].notna()]  # Also remove NaN participants\n",
    "    after_count = combined_data['participant_id'].nunique()\n",
    "    \n",
    "    print(f\"Filtered out test participants and NaN entries\")\n",
    "    print(f\"Participants: {before_count} → {after_count}\")\n",
    "    print(f\"Final dataset shape: {combined_data.shape}\")\n",
    "else:\n",
    "    print(\"No data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data structure\n",
    "print(\"Column names:\")\n",
    "print(combined_data.columns.tolist())\n",
    "print(f\"\\nDataset shape: {combined_data.shape}\")\n",
    "# print(f\"\\nUnique trial types:\")\n",
    "# print(combined_data['trial_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for relevant trial types (prediction tasks and surveys)\n",
    "relevant_trials = combined_data[\n",
    "    combined_data['trial_type'].isin([\n",
    "        'prediction-task', 'vis-literacy', 'trust-survey', \n",
    "        'personality-survey', 'survey-text', 'survey-multi-choice'\n",
    "    ])\n",
    "].copy()\n",
    "\n",
    "print(f\"Filtered dataset shape: {relevant_trials.shape}\")\n",
    "print(f\"\\nTrial types in filtered data:\")\n",
    "print(relevant_trials['trial_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine condition distribution\n",
    "print(\"Unique conditions:\")\n",
    "condition_counts = relevant_trials['condition_id'].value_counts(dropna=False)\n",
    "print(condition_counts)\n",
    "\n",
    "print(\"\\nCondition names:\")\n",
    "condition_names = relevant_trials[['condition_id', 'condition_name']].drop_duplicates().dropna()\n",
    "for _, row in condition_names.iterrows():\n",
    "    print(f\"  {row['condition_id']}: {row['condition_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Phase 1 and Phase 2 data\n",
    "prediction_data = relevant_trials[relevant_trials['trial_type'] == 'prediction-task'].copy()\n",
    "\n",
    "# Phase separation logic\n",
    "phase1_data = prediction_data[prediction_data['phase'] == 1].copy()\n",
    "phase2_data = prediction_data[prediction_data['phase'] == 2].copy()\n",
    "\n",
    "print(f\"Phase 1 data: {len(phase1_data)} rows\")\n",
    "print(f\"Phase 2 data: {len(phase2_data)} rows\")\n",
    "\n",
    "# Get visualization literacy data\n",
    "vis_literacy_data = relevant_trials[relevant_trials['trial_type'] == 'vis-literacy'].copy()\n",
    "print(f\"Visualization literacy data: {len(vis_literacy_data)} rows\")\n",
    "\n",
    "# Separate different types of survey data\n",
    "\n",
    "# Get trust-survey data (interface interaction and visualization trust questions)\n",
    "all_trust_surveys = relevant_trials[relevant_trials['trial_type'] == 'trust-survey'].copy()\n",
    "print(f\"All trust survey data: {len(all_trust_surveys)} rows\")\n",
    "\n",
    "# Get personality survey data (demographics questions)\n",
    "all_personality_surveys = relevant_trials[relevant_trials['trial_type'] == 'personality-survey'].copy()\n",
    "print(f\"All personality survey data: {len(all_personality_surveys)} rows\")\n",
    "\n",
    "# Function to check if a row represents a specific survey type based on question_order\n",
    "def get_survey_type(row):\n",
    "    \"\"\"Determine survey type based on question_order content\"\"\"\n",
    "    if 'question_order' in row and pd.notna(row['question_order']):\n",
    "        try:\n",
    "            question_order = eval(row['question_order'])  # Convert string to list\n",
    "            if isinstance(question_order, list) and len(question_order) > 0:\n",
    "                first_question = question_order[0]\n",
    "                \n",
    "                # Define the first question of each survey type\n",
    "                if first_question == 'navigation_control':\n",
    "                    return 'interaction'\n",
    "                elif first_question == 'skeptical_rating':\n",
    "                    return 'trust'\n",
    "                elif first_question == 'respect_others':\n",
    "                    return 'demographics'\n",
    "        except:\n",
    "            pass\n",
    "    return 'unknown'\n",
    "\n",
    "# Add survey type classification to trust surveys\n",
    "all_trust_surveys['survey_type'] = all_trust_surveys.apply(get_survey_type, axis=1)\n",
    "\n",
    "# Separate the data based on survey types\n",
    "interaction_data = all_trust_surveys[all_trust_surveys['survey_type'] == 'interaction'].copy()\n",
    "trust_data = all_trust_surveys[all_trust_surveys['survey_type'] == 'trust'].copy()\n",
    "demographics_data = all_personality_surveys.copy()  # Demographics is in personality-survey trial type\n",
    "\n",
    "print(f\"Interaction data: {len(interaction_data)} rows\")\n",
    "print(f\"Trust data: {len(trust_data)} rows\") \n",
    "print(f\"Demographics data: {len(demographics_data)} rows\")\n",
    "\n",
    "# Show survey type distribution\n",
    "print(f\"\\nTrust survey type distribution:\")\n",
    "print(all_trust_surveys['survey_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics Tables by Condition\n",
    "\n",
    "Each table shows conditions as rows and response variables as columns, with participant response lists in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_condition_response_table(data, response_columns, title=\"Response Table\"):\n",
    "    \"\"\"\n",
    "    Create a table where each row is a condition and each column is a response variable.\n",
    "    Each cell contains a list of participant responses.\n",
    "    \"\"\"\n",
    "    # Get unique conditions\n",
    "    conditions = sorted(data['condition_id'].dropna().unique())\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    for condition in conditions:\n",
    "        condition_data = data[data['condition_id'] == condition]\n",
    "        condition_responses = {}\n",
    "        \n",
    "        for col in response_columns:\n",
    "            if col in condition_data.columns:\n",
    "                responses = condition_data[col].dropna().tolist()\n",
    "                condition_responses[col] = responses\n",
    "            else:\n",
    "                condition_responses[col] = []\n",
    "        \n",
    "        results[condition] = condition_responses\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results).T\n",
    "    \n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * len(title))\n",
    "    return df\n",
    "\n",
    "# Function to display response summary statistics\n",
    "def display_response_summary(df, title=\"Summary\"):\n",
    "    \"\"\"\n",
    "    Display summary statistics for response lists in each cell\n",
    "    \"\"\"\n",
    "    print(f\"\\n{title} - Response Counts and Basic Stats\")\n",
    "    print(\"-\" * (len(title) + 30))\n",
    "    \n",
    "    for condition in df.index:\n",
    "        print(f\"\\nCondition: {condition}\")\n",
    "        for col in df.columns:\n",
    "            responses = df.loc[condition, col]\n",
    "            if isinstance(responses, list) and responses:\n",
    "                numeric_responses = [r for r in responses if isinstance(r, (int, float)) and not pd.isna(r)]\n",
    "                if numeric_responses:\n",
    "                    print(f\"  {col}: n={len(numeric_responses)}, mean={np.mean(numeric_responses):.2f}, responses={numeric_responses}\")\n",
    "                else:\n",
    "                    print(f\"  {col}: n={len(responses)}, responses={responses[:5]}{'...' if len(responses) > 5 else ''}\")\n",
    "            else:\n",
    "                print(f\"  {col}: No responses\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1 Responses (Baseline - No Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 response columns\n",
    "phase1_columns = ['probability_estimate', 'confidence_rating', 'travel_choice']\n",
    "\n",
    "# Create Phase 1 table\n",
    "phase1_table = create_condition_response_table(\n",
    "    phase1_data, \n",
    "    phase1_columns, \n",
    "    \"Phase 1 Responses (No Visualization)\"\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "display_response_summary(phase1_table, \"Phase 1 Summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 Responses (With Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 response columns\n",
    "phase2_columns = ['probability_estimate', 'confidence_rating', 'travel_choice', 'data_trust', 'skeptical_rating']\n",
    "\n",
    "# Create Phase 2 table\n",
    "phase2_table = create_condition_response_table(\n",
    "    phase2_data, \n",
    "    phase2_columns, \n",
    "    \"Phase 2 Responses (With Visualization)\"\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "display_response_summary(phase2_table, \"Phase 2 Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined dot plot visualization with probability estimates by condition\n",
    "# Opacity based on confidence rating\n",
    "\n",
    "def create_probability_dot_plot():\n",
    "    \"\"\"Create a dot plot showing probability estimates by condition with confidence-based opacity\"\"\"\n",
    "    \n",
    "    # Define condition mapping\n",
    "    condition_names = {\n",
    "        0: \"Historical Only\",\n",
    "        1: \"Baseline\", \n",
    "        2: \"PI Plot\",\n",
    "        3: \"Ensemble Plot\",\n",
    "        4: \"Ensemble + Hover\", \n",
    "        5: \"PI Plot + Hover\",\n",
    "        6: \"PI → Ensemble\",\n",
    "        7: \"Buggy Control\",\n",
    "        8: \"Bad Control\",\n",
    "        9: \"Combined PI + Ensemble\"\n",
    "    }\n",
    "    \n",
    "    # Combine Phase 1 and Phase 2 data for visualization\n",
    "    viz_data = []\n",
    "    \n",
    "    # Add Phase 1 data\n",
    "    for _, row in phase1_data.iterrows():\n",
    "        if pd.notna(row['probability_estimate']) and pd.notna(row['confidence_rating']):\n",
    "            viz_data.append({\n",
    "                'condition_id': row['condition_id'],\n",
    "                'probability_estimate': row['probability_estimate'],\n",
    "                'confidence_rating': row['confidence_rating'],\n",
    "                'phase': 'Phase 1'\n",
    "            })\n",
    "    \n",
    "    # Add Phase 2 data\n",
    "    for _, row in phase2_data.iterrows():\n",
    "        if pd.notna(row['probability_estimate']) and pd.notna(row['confidence_rating']):\n",
    "            viz_data.append({\n",
    "                'condition_id': row['condition_id'],\n",
    "                'probability_estimate': row['probability_estimate'],\n",
    "                'confidence_rating': row['confidence_rating'],\n",
    "                'phase': 'Phase 2'\n",
    "            })\n",
    "    \n",
    "    if not viz_data:\n",
    "        print(\"No data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    viz_df = pd.DataFrame(viz_data)\n",
    "    \n",
    "    # Extract condition numbers for x-axis ordering\n",
    "    def extract_condition_number(condition_id):\n",
    "        if pd.isna(condition_id) or condition_id == 'unknown':\n",
    "            return -1\n",
    "        try:\n",
    "            # Extract number from condition_X_name format\n",
    "            parts = str(condition_id).split('_')\n",
    "            if len(parts) >= 2:\n",
    "                return int(parts[1])\n",
    "        except:\n",
    "            pass\n",
    "        return -1\n",
    "    \n",
    "    viz_df['condition_number'] = viz_df['condition_id'].apply(extract_condition_number)\n",
    "    viz_df = viz_df[viz_df['condition_number'] >= 0]  # Remove unknown conditions\n",
    "    \n",
    "    # Normalize confidence rating to 0-1 for opacity (1-7 scale -> 0-1 scale)\n",
    "    viz_df['opacity'] = (viz_df['confidence_rating'] - 1) / 6  # Convert 1-7 to 0-1\n",
    "    \n",
    "    # Create the combined plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Plot Phase 1 and Phase 2 data with different colors\n",
    "    phase1_viz = viz_df[viz_df['phase'] == 'Phase 1']\n",
    "    phase2_viz = viz_df[viz_df['phase'] == 'Phase 2']\n",
    "    \n",
    "    if len(phase1_viz) > 0:\n",
    "        ax.scatter(phase1_viz['condition_number'], \n",
    "                  phase1_viz['probability_estimate'],\n",
    "                  alpha=phase1_viz['opacity'],\n",
    "                  s=120, c='blue', edgecolors='black', linewidth=1,\n",
    "                  label='Phase 1 (No Forecast)')\n",
    "    \n",
    "    if len(phase2_viz) > 0:\n",
    "        ax.scatter(phase2_viz['condition_number'], \n",
    "                  phase2_viz['probability_estimate'],\n",
    "                  alpha=phase2_viz['opacity'],\n",
    "                  s=120, c='red', edgecolors='black', linewidth=1,\n",
    "                  label='Phase 2 (With Forecast)')\n",
    "    \n",
    "    # Set up the plot\n",
    "    ax.set_title('Probability Estimates by Condition\\n(Dot opacity represents confidence rating)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Experimental Condition', fontsize=12)\n",
    "    ax.set_ylabel('Probability Estimate (%)', fontsize=12)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Force x-axis to show all conditions 0-9\n",
    "    ax.set_xlim(-0.5, 9.5)\n",
    "    ax.set_xticks(range(10))\n",
    "    \n",
    "    # Create condition labels for x-axis\n",
    "    condition_labels = []\n",
    "    for i in range(10):\n",
    "        if i in condition_names:\n",
    "            # Wrap long names for better display\n",
    "            name = condition_names[i]\n",
    "            if len(name) > 12:\n",
    "                words = name.split()\n",
    "                if len(words) > 1:\n",
    "                    mid = len(words) // 2\n",
    "                    name = ' '.join(words[:mid]) + '\\n' + ' '.join(words[mid:])\n",
    "            condition_labels.append(f\"{i}\\n{name}\")\n",
    "        else:\n",
    "            condition_labels.append(f\"{i}\\n(No Data)\")\n",
    "    \n",
    "    ax.set_xticklabels(condition_labels, fontsize=9, ha='center')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    \n",
    "    # Add opacity explanation\n",
    "    fig.text(0.5, 0.02, 'Dot opacity: Low confidence (transparent) → High confidence (opaque)', \n",
    "             ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nVisualization Data Summary:\")\n",
    "    print(f\"Phase 1: {len(phase1_viz)} data points\")\n",
    "    print(f\"Phase 2: {len(phase2_viz)} data points\")\n",
    "    print(f\"Conditions with data: {sorted(viz_df['condition_number'].unique())}\")\n",
    "    \n",
    "    # Show condition mapping\n",
    "    print(f\"\\nCondition Mapping:\")\n",
    "    present_conditions = sorted(viz_df['condition_number'].unique())\n",
    "    for i in range(10):\n",
    "        status = \"✓\" if i in present_conditions else \"✗\"\n",
    "        name = condition_names.get(i, \"Unknown\")\n",
    "        print(f\"  {status} Condition {i}: {name}\")\n",
    "    \n",
    "    return viz_df\n",
    "\n",
    "# Create the visualization\n",
    "viz_summary = create_probability_dot_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust and Usability Measures by Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define question structures for each survey type\n",
    "\n",
    "interactionQuestions = [\n",
    "    {\n",
    "        \"prompt\": \"I was in control of my navigation through this interface.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"navigation_control\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I had some control over the content of this interface that I wanted to see.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"content_control\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I was in control over the pace of my visit to this interface.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"pace_control\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I could communicate with the company directly for further questions about the company or its products if I wanted to.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"company_communication\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"The interface had the ability to respond to my specific questions quickly and efficiently.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"interface_responsiveness\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I could communicate in real time with other customers who shared my interest in this interface.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"customer_communication\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I felt I just had a personal conversation with a sociable, knowledgeable and warm representative from the company.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"personal_conversation\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"The interface was like talking back to me while I clicked through the interface.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"interface_interaction\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I perceived the interface to be sensitive to my needs for product information.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"interface_sensitivity\"\n",
    "    }\n",
    "]\n",
    "\n",
    "visualizationTrustQuestions = [\n",
    "    {\n",
    "        \"prompt\": \"I was skeptical about the information presented in this visualization.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"skeptical_rating\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I trusted this data.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"data_trust\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I found this visualization difficult to use.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"usability_difficulty\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I found this visualization easy to understand.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \"Neutral\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"comprehension_ease\"\n",
    "    }\n",
    "]\n",
    "\n",
    "personalityQuestions = [\n",
    "    {\n",
    "        \"prompt\": \"I respect others.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"respect_others\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I have a good word for everyone.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"good_word_everyone\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I retreat from others.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"retreat_from_others\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I avoid contacts with others.\",\n",
    "        \"labels\": [\"Strongly Disagree\", \"Disagree\", \"Slightly Disagree\", \n",
    "                   \"Slightly Agree\", \"Agree\", \"Strongly Agree\"],\n",
    "        \"type\": \"avoid_contacts\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trust and Usability Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def create_sectioned_trust_plots(data, condition_names, questions, section_title=\"Survey Results\"):\n",
    "    \"\"\"\n",
    "    Create figures with subplots for all questions in the provided question list.\n",
    "    Each subplot shows ratings by condition for that question.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with survey response data\n",
    "        condition_names: Dict mapping condition numbers to names\n",
    "        questions: List of question dictionaries with 'type' and 'prompt' keys\n",
    "        section_title: Title for the overall figure\n",
    "    \"\"\"\n",
    "    if not questions:  # Skip if no questions provided\n",
    "        print(f\"No questions provided for {section_title}\")\n",
    "        return\n",
    "        \n",
    "    n = len(questions)\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=1, figsize=(16, 4*n), sharex=True)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, q in zip(axes, questions):\n",
    "        measure_key = q[\"type\"]\n",
    "        measure_name = q[\"prompt\"]\n",
    "\n",
    "        # Filter data for this measure\n",
    "        measure_data = data[pd.notna(data[measure_key]) & pd.notna(data[\"condition_id\"])]\n",
    "\n",
    "        values, cond_nums = [], []\n",
    "\n",
    "        for _, row in measure_data.iterrows():\n",
    "            try:\n",
    "                cond_num = int(str(row[\"condition_id\"]).split(\"_\")[1])\n",
    "            except:\n",
    "                continue\n",
    "            if cond_num == 0:\n",
    "                continue\n",
    "            values.append(row[measure_key])\n",
    "            cond_nums.append(cond_num)\n",
    "\n",
    "        if len(values) > 0:\n",
    "            ax.scatter(cond_nums, values, alpha=0.7, s=120, edgecolors='black', color=\"#1f77b4\")\n",
    "\n",
    "            # Plot mean per condition\n",
    "            df_plot = pd.DataFrame({\"cond\": cond_nums, \"val\": values})\n",
    "            cond_means = df_plot.groupby(\"cond\")[\"val\"].mean()\n",
    "            for c, mean_val in cond_means.items():\n",
    "                ax.plot([c-0.3, c+0.3], [mean_val, mean_val], \"r-\", linewidth=3, alpha=0.8)\n",
    "\n",
    "        ax.set_title(measure_name, fontsize=12, fontweight=\"bold\", wrap=True)\n",
    "        ax.set_ylim(0.5, 7.5)\n",
    "        ax.set_xlim(0.5, 9.5)\n",
    "        ax.set_xticks(range(1, 10))\n",
    "\n",
    "        # X-axis labels\n",
    "        labels = []\n",
    "        for j in range(1, 10):\n",
    "            name = condition_names.get(j, \"Unknown\")\n",
    "            if len(name) > 10 and \" \" in name:\n",
    "                words = name.split()\n",
    "                mid = len(words) // 2\n",
    "                name = \" \".join(words[:mid]) + \"\\n\" + \" \".join(words[mid:])\n",
    "            labels.append(f\"{j}\\n{name}\")\n",
    "        ax.set_xticklabels(labels, fontsize=9)\n",
    "\n",
    "        ax.set_xlabel(\"Experimental Condition\", fontsize=10)\n",
    "        ax.set_ylabel(\"Rating (1–7)\", fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(section_title, fontsize=16, fontweight=\"bold\", y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract survey responses from JSON response column\n",
    "import json\n",
    "\n",
    "def extract_survey_responses(data):\n",
    "    \"\"\"Extract survey responses from the JSON response column and add as individual columns\"\"\"\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    for idx, row in data_copy.iterrows():\n",
    "        if 'response' in row and pd.notna(row['response']):\n",
    "            try:\n",
    "                # Parse the JSON response data\n",
    "                response_data = json.loads(row['response'])\n",
    "                \n",
    "                # Add each response as a new column\n",
    "                for key, value in response_data.items():\n",
    "                    data_copy.at[idx, key] = value\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing response for row {idx}: {e}\")\n",
    "    \n",
    "    return data_copy\n",
    "\n",
    "print(\"=== EXTRACTING SURVEY RESPONSE DATA ===\")\n",
    "\n",
    "# Extract responses for each dataset\n",
    "print(\"Extracting interaction data responses...\")\n",
    "interaction_data_expanded = extract_survey_responses(interaction_data)\n",
    "\n",
    "print(\"Extracting trust data responses...\")  \n",
    "trust_data_expanded = extract_survey_responses(trust_data)\n",
    "\n",
    "print(\"Extracting demographics data responses...\")\n",
    "demographics_data_expanded = extract_survey_responses(demographics_data)\n",
    "\n",
    "# Check what columns are now available\n",
    "print(f\"\\n=== AFTER EXTRACTION ===\")\n",
    "print(f\"Interaction data shape: {interaction_data_expanded.shape}\")\n",
    "print(\"Interaction data columns:\")\n",
    "interaction_cols = [col for col in interaction_data_expanded.columns if col in ['navigation_control', 'content_control', 'pace_control', 'company_communication', 'interface_responsiveness', 'customer_communication', 'personal_conversation', 'interface_interaction', 'interface_sensitivity']]\n",
    "print(interaction_cols)\n",
    "\n",
    "print(f\"\\nTrust data shape: {trust_data_expanded.shape}\")\n",
    "print(\"Trust data columns:\")\n",
    "trust_cols = [col for col in trust_data_expanded.columns if col in ['skeptical_rating', 'data_trust', 'usability_difficulty', 'comprehension_ease']]\n",
    "print(trust_cols)\n",
    "\n",
    "print(f\"\\nDemographics data shape: {demographics_data_expanded.shape}\")\n",
    "print(\"Demographics data columns:\")\n",
    "demo_cols = [col for col in demographics_data_expanded.columns if col in ['respect_others', 'good_word_everyone', 'retreat_from_others', 'avoid_contacts']]\n",
    "print(demo_cols)\n",
    "\n",
    "# Update the global variables to use the expanded data\n",
    "interaction_data = interaction_data_expanded\n",
    "trust_data = trust_data_expanded  \n",
    "demographics_data = demographics_data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate three separate visualizations for each data type\n",
    "condition_names = {\n",
    "    0: \"Historical Only\",\n",
    "    1: \"Baseline\", \n",
    "    2: \"PI Plot\",\n",
    "    3: \"Ensemble Plot\",\n",
    "    4: \"Ensemble + Hover\", \n",
    "    5: \"PI Plot + Hover\",\n",
    "    6: \"PI → Ensemble\",\n",
    "    7: \"Buggy Control\",\n",
    "    8: \"Bad Control\",\n",
    "    9: \"Combined PI + Ensemble\"\n",
    "}\n",
    "\n",
    "# Create visualization for interaction data\n",
    "print(\"Creating visualization for interface interaction data...\")\n",
    "create_sectioned_trust_plots(\n",
    "    data=interaction_data,\n",
    "    condition_names=condition_names,\n",
    "    questions=interactionQuestions,\n",
    "    section_title=\"Section 1: Interface Interaction & Control\"\n",
    ")\n",
    "\n",
    "# Create visualization for trust data  \n",
    "print(\"\\nCreating visualization for trust/usability data...\")\n",
    "create_sectioned_trust_plots(\n",
    "    data=trust_data,\n",
    "    condition_names=condition_names,\n",
    "    questions=visualizationTrustQuestions,\n",
    "    section_title=\"Section 2: Visualization-Specific Trust\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CONFIGURE YOUR LIKERT QUESTION COLUMNS ---- #\n",
    "# interaction_cols = [\n",
    "#     'navigation_control', 'content_control', 'pace_control',\n",
    "#     'company_communication', 'interface_responsiveness',\n",
    "#     'customer_communication', 'personal_conversation',\n",
    "#     'interface_interaction', 'interface_sensitivity'\n",
    "# ]\n",
    "\n",
    "# trust_cols = [\n",
    "#     'skeptical_rating', 'data_trust', 'usability_difficulty',\n",
    "#     'comprehension_ease'\n",
    "# ]\n",
    "\n",
    "# demo_cols = [\n",
    "#     'respect_others', 'good_word_everyone',\n",
    "#     'retreat_from_others', 'avoid_contacts'\n",
    "# ]\n",
    "\n",
    "# Combine all Likert-scale columns\n",
    "all_question_cols = interaction_cols + trust_cols + demo_cols\n",
    "\n",
    "# ---- MERGE ALL DATASETS ON PARTICIPANT ID ---- #\n",
    "# Replace \"participant_id\" with your ID field name if different\n",
    "merged = (\n",
    "    interaction_data.merge(trust_data, on='participant_id', how='outer')\n",
    "                    .merge(demographics_data, on='participant_id', how='outer')\n",
    ")\n",
    "\n",
    "# Keep only participant + question columns\n",
    "heatmap_df = merged[['participant_id'] + all_question_cols].set_index('participant_id')\n",
    "\n",
    "# Convert all values to numeric (some may be strings)\n",
    "heatmap_df = heatmap_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# ---- CREATE HEATMAP ---- #\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.imshow(heatmap_df, aspect='auto', cmap='Greens', vmin=0, vmax=8)\n",
    "\n",
    "plt.colorbar(label=\"Response (1 = light, 7 = dark)\")\n",
    "plt.title(\"Survey Responses Heatmap (1–7 Likert)\")\n",
    "\n",
    "# Tick labels\n",
    "plt.xticks(ticks=np.arange(len(heatmap_df.columns)), labels=heatmap_df.columns, rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(heatmap_df.index)), labels=heatmap_df.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averaged interaction scores by condition\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Define interaction question columns\n",
    "interaction_cols = ['navigation_control', 'content_control', 'pace_control', \n",
    "                   'company_communication', 'interface_responsiveness', \n",
    "                   'customer_communication', 'personal_conversation', \n",
    "                   'interface_interaction', 'interface_sensitivity']\n",
    "\n",
    "print(\"=== INTERACTION SCORES BY CONDITION ===\")\n",
    "print(\"\\nCalculating averaged interaction scores (1-7 scale)...\")\n",
    "\n",
    "# Calculate average interaction scores for each participant\n",
    "interaction_results = []\n",
    "\n",
    "for _, row in interaction_data.iterrows():\n",
    "    condition_id = row['condition_id']\n",
    "    \n",
    "    # Extract condition number\n",
    "    try:\n",
    "        condition_num = int(str(condition_id).split('_')[1])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    if condition_num == 0:  # Skip condition 0\n",
    "        continue\n",
    "    \n",
    "    # Get all interaction scores for this participant\n",
    "    scores = []\n",
    "    for col in interaction_cols:\n",
    "        if col in row and pd.notna(row[col]):\n",
    "            scores.append(row[col])\n",
    "    \n",
    "    if len(scores) > 0:\n",
    "        avg_score = np.mean(scores)\n",
    "        interaction_results.append({\n",
    "            'condition_id': condition_id,\n",
    "            'condition_num': condition_num,\n",
    "            'participant_id': row['participant_id'],\n",
    "            'avg_interaction_score': avg_score,\n",
    "            'num_questions': len(scores)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(interaction_results)\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    # Calculate statistics by condition\n",
    "    condition_stats = results_df.groupby('condition_num').agg({\n",
    "        'avg_interaction_score': ['mean', 'std', 'count'],\n",
    "        'condition_id': 'first'  # Get the condition ID for reference\n",
    "    }).round(3)\n",
    "    \n",
    "    # Flatten column names\n",
    "    condition_stats.columns = ['mean_score', 'std_score', 'n_participants', 'condition_id']\n",
    "    \n",
    "    # Calculate standard error\n",
    "    condition_stats['se_score'] = (condition_stats['std_score'] / \n",
    "                                  np.sqrt(condition_stats['n_participants'])).round(3)\n",
    "    \n",
    "    # Add condition names\n",
    "    condition_names = {\n",
    "        1: \"Baseline\", \n",
    "        2: \"PI Plot\",\n",
    "        3: \"Ensemble Plot\",\n",
    "        4: \"Ensemble + Hover\", \n",
    "        5: \"PI Plot + Hover\",\n",
    "        6: \"PI → Ensemble\",\n",
    "        7: \"Buggy Control\",\n",
    "        8: \"Bad Control\",\n",
    "        9: \"Combined PI + Ensemble\"\n",
    "    }\n",
    "    \n",
    "    condition_stats['condition_name'] = condition_stats.index.map(condition_names)\n",
    "    \n",
    "    # Sort by mean score (high to low)\n",
    "    condition_stats_ranked = condition_stats.sort_values('mean_score', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== INTERACTION SCORES RANKED BY CONDITION (High to Low) ===\")\n",
    "    print(\"Format: Condition | Mean ± SE | (n participants)\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for rank, (condition_num, row) in enumerate(condition_stats_ranked.iterrows(), 1):\n",
    "        condition_name = row['condition_name']\n",
    "        mean_score = row['mean_score']\n",
    "        se_score = row['se_score']\n",
    "        n = int(row['n_participants'])\n",
    "        \n",
    "        print(f\"{rank:2d}. Condition {condition_num} ({condition_name:18s}) | \"\n",
    "              f\"{mean_score:.2f} ± {se_score:.2f} | (n={n})\")\n",
    "    \n",
    "    # Display detailed breakdown\n",
    "    print(f\"\\n=== DETAILED STATISTICS ===\")\n",
    "    display_cols = ['condition_name', 'mean_score', 'std_score', 'se_score', 'n_participants']\n",
    "    detailed_stats = condition_stats_ranked[display_cols].copy()\n",
    "    detailed_stats.index.name = 'Condition'\n",
    "    print(detailed_stats.to_string())\n",
    "    \n",
    "    # Show individual participant scores for verification\n",
    "    print(f\"\\n=== INDIVIDUAL PARTICIPANT SCORES ===\")\n",
    "    for condition_num in sorted(condition_stats_ranked.index):\n",
    "        condition_name = condition_names.get(condition_num, \"Unknown\")\n",
    "        participant_scores = results_df[results_df['condition_num'] == condition_num]['avg_interaction_score'].tolist()\n",
    "        print(f\"Condition {condition_num} ({condition_name}): {participant_scores}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No interaction data found for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Sort conditions by mean score (high → low) ---\n",
    "condition_stats_sorted = condition_stats.sort_values(\"mean_score\", ascending=False)\n",
    "\n",
    "# Extract plotting data\n",
    "labels = condition_stats_sorted['condition_name'].tolist()\n",
    "means = condition_stats_sorted['mean_score'].tolist()\n",
    "errors = condition_stats_sorted['se_score'].tolist()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Horizontal bar chart with error bars\n",
    "plt.barh(range(len(labels)), means, xerr=errors, capsize=5)\n",
    "plt.gca().invert_yaxis()  # Highest score at top\n",
    "\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "plt.xlabel(\"Average Interaction Score\")\n",
    "plt.title(\"Interaction Scores by Condition (Mean ± SE)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Phase 2 probability estimates and AQI estimates by condition\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== PHASE 2 PREDICTION ESTIMATES BY CONDITION ===\")\n",
    "print(\"\\nCalculating probability estimates and AQI estimates from Phase 2 data...\")\n",
    "\n",
    "# Calculate prediction estimates for each participant in Phase 2\n",
    "prediction_results = []\n",
    "\n",
    "for _, row in phase2_data.iterrows():\n",
    "    condition_id = row['condition_id']\n",
    "    \n",
    "    # Extract condition number\n",
    "    try:\n",
    "        condition_num = int(str(condition_id).split('_')[1])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    if condition_num == 0:  # Skip condition 0 (historical only)\n",
    "        continue\n",
    "    \n",
    "    # Get prediction estimates\n",
    "    probability_est = row.get('probability_estimate')\n",
    "    city_a_est = row.get('city_a_estimate') \n",
    "    city_b_est = row.get('city_b_estimate')\n",
    "    confidence = row.get('confidence_rating')\n",
    "    \n",
    "    if pd.notna(probability_est):  # At minimum need probability estimate\n",
    "        prediction_results.append({\n",
    "            'condition_id': condition_id,\n",
    "            'condition_num': condition_num,\n",
    "            'participant_id': row['participant_id'],\n",
    "            'probability_estimate': probability_est,\n",
    "            'city_a_estimate': city_a_est if pd.notna(city_a_est) else None,\n",
    "            'city_b_estimate': city_b_est if pd.notna(city_b_est) else None,\n",
    "            'confidence_rating': confidence if pd.notna(confidence) else None\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "pred_results_df = pd.DataFrame(prediction_results)\n",
    "\n",
    "if len(pred_results_df) > 0:\n",
    "    # Calculate statistics by condition for each measure\n",
    "    print(\"\\n=== PROBABILITY ESTIMATES (City A > City B) ===\")\n",
    "    prob_stats = pred_results_df.groupby('condition_num').agg({\n",
    "        'probability_estimate': ['mean', 'std', 'count'],\n",
    "        'condition_id': 'first'\n",
    "    }).round(2)\n",
    "    prob_stats.columns = ['mean_prob', 'std_prob', 'n_prob', 'condition_id']\n",
    "    prob_stats['se_prob'] = (prob_stats['std_prob'] / np.sqrt(prob_stats['n_prob'])).round(2)\n",
    "    \n",
    "    # City A estimates\n",
    "    print(\"\\n=== CITY A AQI ESTIMATES ===\") \n",
    "    city_a_data = pred_results_df[pred_results_df['city_a_estimate'].notna()]\n",
    "    if len(city_a_data) > 0:\n",
    "        city_a_stats = city_a_data.groupby('condition_num').agg({\n",
    "            'city_a_estimate': ['mean', 'std', 'count'],\n",
    "            'condition_id': 'first'\n",
    "        }).round(2)\n",
    "        city_a_stats.columns = ['mean_city_a', 'std_city_a', 'n_city_a', 'condition_id']\n",
    "        city_a_stats['se_city_a'] = (city_a_stats['std_city_a'] / np.sqrt(city_a_stats['n_city_a'])).round(2)\n",
    "    else:\n",
    "        city_a_stats = pd.DataFrame()\n",
    "    \n",
    "    # City B estimates  \n",
    "    print(\"\\n=== CITY B AQI ESTIMATES ===\")\n",
    "    city_b_data = pred_results_df[pred_results_df['city_b_estimate'].notna()]\n",
    "    if len(city_b_data) > 0:\n",
    "        city_b_stats = city_b_data.groupby('condition_num').agg({\n",
    "            'city_b_estimate': ['mean', 'std', 'count'], \n",
    "            'condition_id': 'first'\n",
    "        }).round(2)\n",
    "        city_b_stats.columns = ['mean_city_b', 'std_city_b', 'n_city_b', 'condition_id']\n",
    "        city_b_stats['se_city_b'] = (city_b_stats['std_city_b'] / np.sqrt(city_b_stats['n_city_b'])).round(2)\n",
    "    else:\n",
    "        city_b_stats = pd.DataFrame()\n",
    "    \n",
    "    # Combine all statistics\n",
    "    combined_stats = prob_stats.copy()\n",
    "    if not city_a_stats.empty:\n",
    "        combined_stats = combined_stats.join(city_a_stats[['mean_city_a', 'se_city_a', 'n_city_a']], how='left')\n",
    "    if not city_b_stats.empty:\n",
    "        combined_stats = combined_stats.join(city_b_stats[['mean_city_b', 'se_city_b', 'n_city_b']], how='left')\n",
    "    \n",
    "    # Add condition names\n",
    "    condition_names = {\n",
    "        1: \"Baseline\", \n",
    "        2: \"PI Plot\",\n",
    "        3: \"Ensemble Plot\",\n",
    "        4: \"Ensemble + Hover\", \n",
    "        5: \"PI Plot + Hover\",\n",
    "        6: \"PI → Ensemble\",\n",
    "        7: \"Buggy Control\",\n",
    "        8: \"Bad Control\",\n",
    "        9: \"Combined PI + Ensemble\"\n",
    "    }\n",
    "    combined_stats['condition_name'] = combined_stats.index.map(condition_names)\n",
    "    \n",
    "    # Sort by probability estimate (LOW to HIGH - lower probability ranked higher)\n",
    "    combined_stats_ranked = combined_stats.sort_values('mean_prob', ascending=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PHASE 2 PREDICTION ESTIMATES RANKED BY PROBABILITY (Low to High)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Format: Condition | P(City A > City B) | City A AQI | City B AQI | (n)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for rank, (condition_num, row) in enumerate(combined_stats_ranked.iterrows(), 1):\n",
    "        condition_name = row['condition_name']\n",
    "        \n",
    "        # Probability estimate\n",
    "        prob_mean = row['mean_prob']\n",
    "        prob_se = row['se_prob']\n",
    "        n_prob = int(row['n_prob'])\n",
    "        \n",
    "        # City A estimate\n",
    "        if pd.notna(row.get('mean_city_a')):\n",
    "            city_a_mean = row['mean_city_a']\n",
    "            city_a_se = row['se_city_a']\n",
    "            city_a_str = f\"{city_a_mean:.1f} ± {city_a_se:.1f}\"\n",
    "        else:\n",
    "            city_a_str = \"N/A\"\n",
    "        \n",
    "        # City B estimate  \n",
    "        if pd.notna(row.get('mean_city_b')):\n",
    "            city_b_mean = row['mean_city_b']\n",
    "            city_b_se = row['se_city_b']\n",
    "            city_b_str = f\"{city_b_mean:.1f} ± {city_b_se:.1f}\"\n",
    "        else:\n",
    "            city_b_str = \"N/A\"\n",
    "        \n",
    "        print(f\"{rank:2d}. Condition {condition_num} ({condition_name:18s}) | \"\n",
    "              f\"{prob_mean:5.1f}% ± {prob_se:4.1f} | {city_a_str:>12s} | {city_b_str:>12s} | (n={n_prob})\")\n",
    "    \n",
    "    # Detailed breakdown\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED STATISTICS TABLE\")\n",
    "    print(\"=\"*60)\n",
    "    display_cols = ['condition_name', 'mean_prob', 'se_prob', 'n_prob']\n",
    "    if not city_a_stats.empty:\n",
    "        display_cols.extend(['mean_city_a', 'se_city_a'])\n",
    "    if not city_b_stats.empty:\n",
    "        display_cols.extend(['mean_city_b', 'se_city_b'])\n",
    "    \n",
    "    detailed_pred_stats = combined_stats_ranked[display_cols].copy()\n",
    "    detailed_pred_stats.index.name = 'Condition'\n",
    "    print(detailed_pred_stats.to_string())\n",
    "    \n",
    "    # Individual participant data for verification\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"INDIVIDUAL PARTICIPANT ESTIMATES\")\n",
    "    print(\"=\"*60)\n",
    "    for condition_num in sorted(combined_stats_ranked.index):\n",
    "        condition_name = condition_names.get(condition_num, \"Unknown\")\n",
    "        condition_data = pred_results_df[pred_results_df['condition_num'] == condition_num]\n",
    "        \n",
    "        prob_values = condition_data['probability_estimate'].tolist()\n",
    "        city_a_values = condition_data['city_a_estimate'].dropna().tolist()\n",
    "        city_b_values = condition_data['city_b_estimate'].dropna().tolist()\n",
    "        \n",
    "        print(f\"\\nCondition {condition_num} ({condition_name}):\")\n",
    "        print(f\"  Probability estimates: {prob_values}\")\n",
    "        if city_a_values:\n",
    "            print(f\"  City A AQI estimates: {city_a_values}\")\n",
    "        if city_b_values:\n",
    "            print(f\"  City B AQI estimates: {city_b_values}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No Phase 2 prediction data found for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](SCR-20251208-ovoi-1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
