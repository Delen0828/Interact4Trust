{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Prediction Study Analysis\n",
    "\n",
    "This notebook analyzes experimental data from the trust and uncertainty visualization study.\n",
    "The study examines how different visualization conditions affect user trust, confidence, and decision-making across two phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 participant data files:\n",
      "  - user_6657381117794993965781_2025-12-08T17-16-29-651.csv\n",
      "  - user_67425624930886458_2025-12-08T17-23-33-555.csv\n",
      "  - user_9830_2025-12-08T04-16-47-915.csv\n",
      "  - user_1765213036676_2025-12-08T16-57-16-674.csv\n",
      "  - user_62199458482518274623771_2025-12-08T17-37-25-103.csv\n"
     ]
    }
   ],
   "source": [
    "# Load all CSV files from the data directory\n",
    "data_dir = Path('./data')\n",
    "csv_files = list(data_dir.glob('user_*.csv'))\n",
    "print(f\"Found {len(csv_files)} participant data files:\")\n",
    "for file in csv_files:\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for participant: 66573c811d17794993965781\n",
      "Loaded data for participant: 67aced4b25f62493088645b8\n",
      "Loaded data for participant: nan\n",
      "Loaded data for participant: test\n",
      "Loaded data for participant: 62e199458482518274623771\n",
      "\n",
      "Combined dataset shape: (92, 46)\n"
     ]
    }
   ],
   "source": [
    "# Function to load and clean individual participant data\n",
    "def load_participant_data(file_path):\n",
    "    \"\"\"Load a single participant CSV file and clean the data\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Extract participant ID from filename if not in data\n",
    "        if 'participant_id' not in df.columns or df['participant_id'].isna().all():\n",
    "            participant_id = file_path.stem.split('_')[1]  # Extract from filename\n",
    "            df['participant_id'] = participant_id\n",
    "        \n",
    "        # Clean condition IDs and names\n",
    "        if 'condition_id' in df.columns:\n",
    "            df['condition_id'] = df['condition_id'].fillna('unknown')\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load all participant data\n",
    "all_data = []\n",
    "for file_path in csv_files:\n",
    "    participant_data = load_participant_data(file_path)\n",
    "    if participant_data is not None:\n",
    "        all_data.append(participant_data)\n",
    "        print(f\"Loaded data for participant: {participant_data['participant_id'].iloc[0] if not participant_data['participant_id'].isna().all() else 'unknown'}\")\n",
    "\n",
    "# Combine all participant data\n",
    "if all_data:\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nCombined dataset shape: {combined_data.shape}\")\n",
    "else:\n",
    "    print(\"No data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['city_a_estimate', 'city_b_estimate', 'click_events', 'comprehension_ease', 'condition', 'condition_id', 'condition_name', 'confidence_label', 'confidence_rating', 'data_trust', 'display_format', 'end_time', 'hover_events', 'interaction_log', 'internal_node_id', 'participant_id', 'percent_score', 'phase', 'phase1_complete', 'phase2_complete', 'predictions_shown', 'probability_estimate', 'question_order', 'response', 'responses', 'round', 'rt', 'rt_total', 'skeptical_rating', 'start_time', 'stimulus', 'success', 'time_elapsed', 'time_on_viz', 'total_interactions', 'total_questions', 'total_score', 'travel_choice', 'trial_index', 'trial_type', 'trust_composite', 'usability_composite', 'usability_difficulty', 'view_history', 'visualization_literacy_score', 'visualization_shown']\n",
      "\n",
      "Dataset shape: (92, 46)\n",
      "\n",
      "Unique trial types:\n",
      "trial_type\n",
      "html-button-response    30\n",
      "prediction-task         10\n",
      "trust-survey            10\n",
      "survey-text              9\n",
      "fullscreen               8\n",
      "vis-literacy             5\n",
      "instructions             5\n",
      "personality-survey       5\n",
      "survey-multi-choice      5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the data structure\n",
    "print(\"Column names:\")\n",
    "print(combined_data.columns.tolist())\n",
    "print(f\"\\nDataset shape: {combined_data.shape}\")\n",
    "print(f\"\\nUnique trial types:\")\n",
    "print(combined_data['trial_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset shape: (44, 46)\n",
      "\n",
      "Trial types in filtered data:\n",
      "trial_type\n",
      "prediction-task        10\n",
      "trust-survey           10\n",
      "survey-text             9\n",
      "vis-literacy            5\n",
      "personality-survey      5\n",
      "survey-multi-choice     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter for relevant trial types (prediction tasks and surveys)\n",
    "relevant_trials = combined_data[\n",
    "    combined_data['trial_type'].isin([\n",
    "        'prediction-task', 'vis-literacy', 'trust-survey', \n",
    "        'personality-survey', 'survey-text', 'survey-multi-choice'\n",
    "    ])\n",
    "].copy()\n",
    "\n",
    "print(f\"Filtered dataset shape: {relevant_trials.shape}\")\n",
    "print(f\"\\nTrial types in filtered data:\")\n",
    "print(relevant_trials['trial_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique conditions:\n",
      "condition_id\n",
      "condition_7_buggy         14\n",
      "condition_9_combined      14\n",
      "condition_5_pi_hover       7\n",
      "condition_0_historical     5\n",
      "unknown                    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Condition names:\n",
      "  condition_7_buggy: Buggy Control\n",
      "  condition_0_historical: Historical Only\n",
      "  condition_5_pi_hover: PI Plot + Hover\n",
      "  condition_9_combined: Combined PI + Ensemble\n"
     ]
    }
   ],
   "source": [
    "# Examine condition distribution\n",
    "print(\"Unique conditions:\")\n",
    "condition_counts = relevant_trials['condition_id'].value_counts(dropna=False)\n",
    "print(condition_counts)\n",
    "\n",
    "print(\"\\nCondition names:\")\n",
    "condition_names = relevant_trials[['condition_id', 'condition_name']].drop_duplicates().dropna()\n",
    "for _, row in condition_names.iterrows():\n",
    "    print(f\"  {row['condition_id']}: {row['condition_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 data: 5 rows\n",
      "Phase 2 data: 5 rows\n",
      "Visualization literacy data: 5 rows\n",
      "Trust survey data: 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Separate Phase 1 and Phase 2 data\n",
    "prediction_data = relevant_trials[relevant_trials['trial_type'] == 'prediction-task'].copy()\n",
    "\n",
    "# Phase separation logic\n",
    "phase1_data = prediction_data[prediction_data['phase'] == 1].copy()\n",
    "phase2_data = prediction_data[prediction_data['phase'] == 2].copy()\n",
    "\n",
    "print(f\"Phase 1 data: {len(phase1_data)} rows\")\n",
    "print(f\"Phase 2 data: {len(phase2_data)} rows\")\n",
    "\n",
    "# Get visualization literacy data\n",
    "vis_literacy_data = relevant_trials[relevant_trials['trial_type'] == 'vis-literacy'].copy()\n",
    "print(f\"Visualization literacy data: {len(vis_literacy_data)} rows\")\n",
    "\n",
    "# Get trust survey data\n",
    "trust_data = relevant_trials[relevant_trials['trial_type'] == 'trust-survey'].copy()\n",
    "print(f\"Trust survey data: {len(trust_data)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics Tables by Condition\n",
    "\n",
    "Each table shows conditions as rows and response variables as columns, with participant response lists in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_condition_response_table(data, response_columns, title=\"Response Table\"):\n",
    "    \"\"\"\n",
    "    Create a table where each row is a condition and each column is a response variable.\n",
    "    Each cell contains a list of participant responses.\n",
    "    \"\"\"\n",
    "    # Get unique conditions\n",
    "    conditions = sorted(data['condition_id'].dropna().unique())\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    for condition in conditions:\n",
    "        condition_data = data[data['condition_id'] == condition]\n",
    "        condition_responses = {}\n",
    "        \n",
    "        for col in response_columns:\n",
    "            if col in condition_data.columns:\n",
    "                responses = condition_data[col].dropna().tolist()\n",
    "                condition_responses[col] = responses\n",
    "            else:\n",
    "                condition_responses[col] = []\n",
    "        \n",
    "        results[condition] = condition_responses\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results).T\n",
    "    \n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * len(title))\n",
    "    return df\n",
    "\n",
    "# Function to display response summary statistics\n",
    "def display_response_summary(df, title=\"Summary\"):\n",
    "    \"\"\"\n",
    "    Display summary statistics for response lists in each cell\n",
    "    \"\"\"\n",
    "    print(f\"\\n{title} - Response Counts and Basic Stats\")\n",
    "    print(\"-\" * (len(title) + 30))\n",
    "    \n",
    "    for condition in df.index:\n",
    "        print(f\"\\nCondition: {condition}\")\n",
    "        for col in df.columns:\n",
    "            responses = df.loc[condition, col]\n",
    "            if isinstance(responses, list) and responses:\n",
    "                numeric_responses = [r for r in responses if isinstance(r, (int, float)) and not pd.isna(r)]\n",
    "                if numeric_responses:\n",
    "                    print(f\"  {col}: n={len(numeric_responses)}, mean={np.mean(numeric_responses):.2f}, responses={numeric_responses}\")\n",
    "                else:\n",
    "                    print(f\"  {col}: n={len(responses)}, responses={responses[:5]}{'...' if len(responses) > 5 else ''}\")\n",
    "            else:\n",
    "                print(f\"  {col}: No responses\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1 Responses (Baseline - No Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 1 Responses (No Visualization)\n",
      "====================================\n",
      "\n",
      "Phase 1 Summary - Response Counts and Basic Stats\n",
      "---------------------------------------------\n",
      "\n",
      "Condition: condition_0_historical\n",
      "  probability_estimate: n=5, mean=70.00, responses=[80.0, 88.0, 50.0, 50.0, 82.0]\n",
      "  confidence_rating: n=5, mean=3.80, responses=[5.0, 4.0, 3.0, 2.0, 5.0]\n",
      "  travel_choice: n=5, responses=['City A', 'City A', 'No Preference', 'No Preference', 'City A']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability_estimate</th>\n",
       "      <th>confidence_rating</th>\n",
       "      <th>travel_choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>condition_0_historical</th>\n",
       "      <td>[80.0, 88.0, 50.0, 50.0, 82.0]</td>\n",
       "      <td>[5.0, 4.0, 3.0, 2.0, 5.0]</td>\n",
       "      <td>[City A, City A, No Preference, No Preference,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  probability_estimate  \\\n",
       "condition_0_historical  [80.0, 88.0, 50.0, 50.0, 82.0]   \n",
       "\n",
       "                                confidence_rating  \\\n",
       "condition_0_historical  [5.0, 4.0, 3.0, 2.0, 5.0]   \n",
       "\n",
       "                                                            travel_choice  \n",
       "condition_0_historical  [City A, City A, No Preference, No Preference,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Phase 1 response columns\n",
    "phase1_columns = ['probability_estimate', 'confidence_rating', 'travel_choice']\n",
    "\n",
    "# Create Phase 1 table\n",
    "phase1_table = create_condition_response_table(\n",
    "    phase1_data, \n",
    "    phase1_columns, \n",
    "    \"Phase 1 Responses (No Visualization)\"\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "display_response_summary(phase1_table, \"Phase 1 Summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 Responses (With Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 2 Responses (With Visualization)\n",
      "======================================\n",
      "\n",
      "Phase 2 Summary - Response Counts and Basic Stats\n",
      "---------------------------------------------\n",
      "\n",
      "Condition: condition_5_pi_hover\n",
      "  probability_estimate: n=1, mean=86.00, responses=[86.0]\n",
      "  confidence_rating: n=1, mean=5.00, responses=[5.0]\n",
      "  travel_choice: n=1, responses=['City A']\n",
      "  data_trust: No responses\n",
      "  skeptical_rating: No responses\n",
      "\n",
      "Condition: condition_7_buggy\n",
      "  probability_estimate: n=2, mean=75.00, responses=[100.0, 50.0]\n",
      "  confidence_rating: n=2, mean=4.50, responses=[6.0, 3.0]\n",
      "  travel_choice: n=2, responses=['City A', 'No Preference']\n",
      "  data_trust: No responses\n",
      "  skeptical_rating: No responses\n",
      "\n",
      "Condition: condition_9_combined\n",
      "  probability_estimate: n=2, mean=67.50, responses=[50.0, 85.0]\n",
      "  confidence_rating: n=2, mean=4.50, responses=[3.0, 6.0]\n",
      "  travel_choice: n=2, responses=['No Preference', 'City A']\n",
      "  data_trust: No responses\n",
      "  skeptical_rating: No responses\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability_estimate</th>\n",
       "      <th>confidence_rating</th>\n",
       "      <th>travel_choice</th>\n",
       "      <th>data_trust</th>\n",
       "      <th>skeptical_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>condition_5_pi_hover</th>\n",
       "      <td>[86.0]</td>\n",
       "      <td>[5.0]</td>\n",
       "      <td>[City A]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition_7_buggy</th>\n",
       "      <td>[100.0, 50.0]</td>\n",
       "      <td>[6.0, 3.0]</td>\n",
       "      <td>[City A, No Preference]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition_9_combined</th>\n",
       "      <td>[50.0, 85.0]</td>\n",
       "      <td>[3.0, 6.0]</td>\n",
       "      <td>[No Preference, City A]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     probability_estimate confidence_rating  \\\n",
       "condition_5_pi_hover               [86.0]             [5.0]   \n",
       "condition_7_buggy           [100.0, 50.0]        [6.0, 3.0]   \n",
       "condition_9_combined         [50.0, 85.0]        [3.0, 6.0]   \n",
       "\n",
       "                                travel_choice data_trust skeptical_rating  \n",
       "condition_5_pi_hover                 [City A]         []               []  \n",
       "condition_7_buggy     [City A, No Preference]         []               []  \n",
       "condition_9_combined  [No Preference, City A]         []               []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Phase 2 response columns\n",
    "phase2_columns = ['probability_estimate', 'confidence_rating', 'travel_choice', 'data_trust', 'skeptical_rating']\n",
    "\n",
    "# Create Phase 2 table\n",
    "phase2_table = create_condition_response_table(\n",
    "    phase2_data, \n",
    "    phase2_columns, \n",
    "    \"Phase 2 Responses (With Visualization)\"\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "display_response_summary(phase2_table, \"Phase 2 Summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Visualization Literacy Question Responses by Condition"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Function to parse visualization literacy responses\ndef parse_vis_literacy_responses(responses_str):\n    \"\"\"Parse the JSON responses from visualization literacy test\"\"\"\n    if pd.isna(responses_str):\n        return []\n    try:\n        # Clean and parse JSON\n        cleaned_str = responses_str.replace(\"'\", '\"')\n        responses = json.loads(cleaned_str)\n        return responses\n    except:\n        return []\n\n# Parse visualization literacy responses\nprint(\"=== VISUALIZATION LITERACY RESPONSES ===\")\nprint(\"\\nIndividual Question Responses by Participant:\")\nprint(\"-\" * 50)\n\nvis_lit_responses = {}\nfor idx, row in vis_literacy_data.iterrows():\n    participant_id = row['participant_id']\n    condition_id = row['condition_id']\n    responses = parse_vis_literacy_responses(row['responses'])\n    \n    if responses:\n        print(f\"\\nParticipant: {participant_id} (Condition: {condition_id})\")\n        print(f\"Total Questions: {len(responses)}\")\n        \n        # Store responses for table creation\n        vis_lit_responses[participant_id] = {\n            'condition_id': condition_id,\n            'responses': responses\n        }\n        \n        # Display first few responses as example\n        for i, q in enumerate(responses[:3]):\n            question_id = q.get('question_id', f'Q{i+1}')\n            question_type = q.get('question_type', 'unknown')\n            response = q.get('response', 'N/A')\n            is_correct = q.get('is_correct', False)\n            print(f\"  {question_id} ({question_type}): Response={response}, Correct={is_correct}\")\n        \n        if len(responses) > 3:\n            print(f\"  ... and {len(responses) - 3} more questions\")\n    else:\n        print(f\"\\nParticipant: {participant_id} - No responses found\")\n\n# Create a summary table of correct/incorrect responses by question type\nprint(\"\\n\\n=== QUESTION TYPE PERFORMANCE SUMMARY ===\")\nquestion_performance = {}\n\nfor participant_id, data in vis_lit_responses.items():\n    condition = data['condition_id']\n    for q in data['responses']:\n        question_type = q.get('question_type', 'unknown')\n        is_correct = q.get('is_correct', False)\n        response = q.get('response', 'N/A')\n        \n        if condition not in question_performance:\n            question_performance[condition] = {}\n        \n        if question_type not in question_performance[condition]:\n            question_performance[condition][question_type] = []\n        \n        question_performance[condition][question_type].append({\n            'participant': participant_id,\n            'response': response,\n            'correct': is_correct\n        })\n\n# Display performance by condition and question type\nfor condition in sorted(question_performance.keys()):\n    print(f\"\\nCondition: {condition}\")\n    print(\"-\" * (len(condition) + 12))\n    \n    for question_type in sorted(question_performance[condition].keys()):\n        responses = question_performance[condition][question_type]\n        correct_count = sum(1 for r in responses if r['correct'])\n        total_count = len(responses)\n        accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0\n        \n        print(f\"  {question_type}: {correct_count}/{total_count} correct ({accuracy:.1f}%)\")\n        \n        # Show individual responses\n        response_list = [r['response'] for r in responses]\n        print(f\"    Responses: {response_list}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust and Usability Measures by Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust survey columns:\n",
      "['comprehension_ease', 'data_trust', 'skeptical_rating', 'trust_composite', 'usability_composite', 'usability_difficulty']\n",
      "\n",
      "Trust and Usability Measures by Condition\n",
      "=========================================\n",
      "\n",
      "Trust and Usability Summary - Response Counts and Basic Stats\n",
      "---------------------------------------------------------\n",
      "\n",
      "Condition: condition_5_pi_hover\n",
      "  trust_composite: n=1, mean=5.00, responses=[5.0]\n",
      "  usability_composite: n=1, mean=5.00, responses=[5.0]\n",
      "  data_trust: n=1, mean=5.00, responses=[5.0]\n",
      "  skeptical_rating: n=1, mean=3.00, responses=[3.0]\n",
      "  usability_difficulty: n=1, mean=3.00, responses=[3.0]\n",
      "  comprehension_ease: n=1, mean=5.00, responses=[5.0]\n",
      "\n",
      "Condition: condition_7_buggy\n",
      "  trust_composite: n=2, mean=2.00, responses=[2.0, 2.0]\n",
      "  usability_composite: n=2, mean=5.00, responses=[6.0, 4.0]\n",
      "  data_trust: n=2, mean=2.00, responses=[2.0, 2.0]\n",
      "  skeptical_rating: n=2, mean=5.00, responses=[6.0, 4.0]\n",
      "  usability_difficulty: n=2, mean=3.50, responses=[2.0, 5.0]\n",
      "  comprehension_ease: n=2, mean=5.00, responses=[6.0, 4.0]\n",
      "\n",
      "Condition: condition_9_combined\n",
      "  trust_composite: n=2, mean=3.00, responses=[4.0, 2.0]\n",
      "  usability_composite: n=2, mean=3.50, responses=[4.0, 3.0]\n",
      "  data_trust: n=2, mean=3.00, responses=[4.0, 2.0]\n",
      "  skeptical_rating: n=2, mean=5.00, responses=[4.0, 6.0]\n",
      "  usability_difficulty: n=2, mean=4.50, responses=[4.0, 5.0]\n",
      "  comprehension_ease: n=2, mean=3.50, responses=[4.0, 3.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trust_composite</th>\n",
       "      <th>usability_composite</th>\n",
       "      <th>data_trust</th>\n",
       "      <th>skeptical_rating</th>\n",
       "      <th>usability_difficulty</th>\n",
       "      <th>comprehension_ease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>condition_5_pi_hover</th>\n",
       "      <td>[5.0]</td>\n",
       "      <td>[5.0]</td>\n",
       "      <td>[5.0]</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>[5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition_7_buggy</th>\n",
       "      <td>[2.0, 2.0]</td>\n",
       "      <td>[6.0, 4.0]</td>\n",
       "      <td>[2.0, 2.0]</td>\n",
       "      <td>[6.0, 4.0]</td>\n",
       "      <td>[2.0, 5.0]</td>\n",
       "      <td>[6.0, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition_9_combined</th>\n",
       "      <td>[4.0, 2.0]</td>\n",
       "      <td>[4.0, 3.0]</td>\n",
       "      <td>[4.0, 2.0]</td>\n",
       "      <td>[4.0, 6.0]</td>\n",
       "      <td>[4.0, 5.0]</td>\n",
       "      <td>[4.0, 3.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trust_composite usability_composite  data_trust  \\\n",
       "condition_5_pi_hover           [5.0]               [5.0]       [5.0]   \n",
       "condition_7_buggy         [2.0, 2.0]          [6.0, 4.0]  [2.0, 2.0]   \n",
       "condition_9_combined      [4.0, 2.0]          [4.0, 3.0]  [4.0, 2.0]   \n",
       "\n",
       "                     skeptical_rating usability_difficulty comprehension_ease  \n",
       "condition_5_pi_hover            [3.0]                [3.0]              [5.0]  \n",
       "condition_7_buggy          [6.0, 4.0]           [2.0, 5.0]         [6.0, 4.0]  \n",
       "condition_9_combined       [4.0, 6.0]           [4.0, 5.0]         [4.0, 3.0]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine trust survey data structure\n",
    "print(\"Trust survey columns:\")\n",
    "trust_cols = [col for col in trust_data.columns if any(keyword in col.lower() for keyword in ['trust', 'usability', 'skeptical', 'comprehension'])]\n",
    "print(trust_cols)\n",
    "\n",
    "# Trust and usability response columns\n",
    "trust_columns = ['trust_composite', 'usability_composite', 'data_trust', 'skeptical_rating', 'usability_difficulty', 'comprehension_ease']\n",
    "\n",
    "# Create trust measures table\n",
    "trust_table = create_condition_response_table(\n",
    "    trust_data, \n",
    "    trust_columns, \n",
    "    \"Trust and Usability Measures by Condition\"\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "display_response_summary(trust_table, \"Trust and Usability Summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY ASSESSMENT ===\n",
      "\n",
      "1. Participation Completion Rates\n",
      "-----------------------------------\n",
      "Total participants: 5\n",
      "Phase 1 completed: 5\n",
      "Phase 2 completed: 5\n",
      "Both phases completed: 5\n",
      "\n",
      "Completion by condition:\n",
      "              total_participants  phase1_complete  phase2_complete\n",
      "condition_id                                                      \n",
      "unknown                        5                5                5\n"
     ]
    }
   ],
   "source": [
    "# Participation completion rates\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "print(\"\\n1. Participation Completion Rates\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Check completion by participant\n",
    "participant_completion = combined_data.groupby('participant_id').agg({\n",
    "    'trial_type': list,\n",
    "    'phase1_complete': 'any',\n",
    "    'phase2_complete': 'any',\n",
    "    'condition_id': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"Total participants: {len(participant_completion)}\")\n",
    "print(f\"Phase 1 completed: {participant_completion['phase1_complete'].sum()}\")\n",
    "print(f\"Phase 2 completed: {participant_completion['phase2_complete'].sum()}\")\n",
    "print(f\"Both phases completed: {(participant_completion['phase1_complete'] & participant_completion['phase2_complete']).sum()}\")\n",
    "\n",
    "print(\"\\nCompletion by condition:\")\n",
    "completion_by_condition = participant_completion.groupby('condition_id').agg({\n",
    "    'participant_id': 'count',\n",
    "    'phase1_complete': 'sum',\n",
    "    'phase2_complete': 'sum'\n",
    "}).rename(columns={'participant_id': 'total_participants'})\n",
    "print(completion_by_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Response Time Analysis\n",
      "-------------------------\n",
      "Prediction task response times (ms):\n",
      "  Mean: 40141 ms\n",
      "  Median: 43091 ms\n",
      "  Min: 5149 ms\n",
      "  Max: 84929 ms\n",
      "\n",
      "Response times by phase:\n",
      "       count     mean   median\n",
      "phase                         \n",
      "1.0        5  55413.0  58067.0\n",
      "2.0        5  24868.0  22476.0\n"
     ]
    }
   ],
   "source": [
    "# Response time analysis\n",
    "print(\"\\n2. Response Time Analysis\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Get response times for prediction tasks\n",
    "prediction_rt = prediction_data[prediction_data['rt'].notna()]\n",
    "if len(prediction_rt) > 0:\n",
    "    print(f\"Prediction task response times (ms):\")\n",
    "    print(f\"  Mean: {prediction_rt['rt'].mean():.0f} ms\")\n",
    "    print(f\"  Median: {prediction_rt['rt'].median():.0f} ms\")\n",
    "    print(f\"  Min: {prediction_rt['rt'].min():.0f} ms\")\n",
    "    print(f\"  Max: {prediction_rt['rt'].max():.0f} ms\")\n",
    "    \n",
    "    # Response times by phase\n",
    "    print(\"\\nResponse times by phase:\")\n",
    "    phase_rt = prediction_rt.groupby('phase')['rt'].agg(['count', 'mean', 'median']).round(0)\n",
    "    print(phase_rt)\n",
    "else:\n",
    "    print(\"No response time data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Missing Data Patterns\n",
      "-------------------------\n",
      "Missing data for key variables:\n",
      "                              missing_count  missing_pct\n",
      "probability_estimate                   34.0         77.3\n",
      "confidence_rating                      34.0         77.3\n",
      "data_trust                             39.0         88.6\n",
      "visualization_literacy_score           44.0        100.0\n"
     ]
    }
   ],
   "source": [
    "# Missing data patterns\n",
    "print(\"\\n3. Missing Data Patterns\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Key variables missing data\n",
    "key_vars = ['probability_estimate', 'confidence_rating', 'data_trust', 'visualization_literacy_score']\n",
    "missing_data = {}\n",
    "\n",
    "for var in key_vars:\n",
    "    if var in relevant_trials.columns:\n",
    "        total_rows = len(relevant_trials)\n",
    "        missing_count = relevant_trials[var].isna().sum()\n",
    "        missing_pct = (missing_count / total_rows) * 100\n",
    "        missing_data[var] = {'missing_count': missing_count, 'missing_pct': missing_pct}\n",
    "\n",
    "missing_df = pd.DataFrame(missing_data).T\n",
    "print(\"Missing data for key variables:\")\n",
    "print(missing_df.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAMPLE DEMOGRAPHICS ===\n",
      "\n",
      "1. Participant Counts by Condition\n",
      "-----------------------------------\n",
      "          condition_id         condition_name  participant_count\n",
      "condition_0_historical        Historical Only                  4\n",
      "  condition_5_pi_hover        PI Plot + Hover                  1\n",
      "     condition_7_buggy          Buggy Control                  1\n",
      "  condition_9_combined Combined PI + Ensemble                  2\n",
      "\n",
      "Total unique participants: 4\n"
     ]
    }
   ],
   "source": [
    "# Participant counts per condition\n",
    "print(\"=== SAMPLE DEMOGRAPHICS ===\")\n",
    "print(\"\\n1. Participant Counts by Condition\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Get unique participants per condition\n",
    "participant_counts = relevant_trials.groupby(['condition_id', 'condition_name']).agg({\n",
    "    'participant_id': 'nunique'\n",
    "}).rename(columns={'participant_id': 'participant_count'}).reset_index()\n",
    "\n",
    "print(participant_counts.to_string(index=False))\n",
    "print(f\"\\nTotal unique participants: {relevant_trials['participant_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Basic Demographics\n",
      "--------------------\n",
      "Text survey responses available: 9\n",
      "Multi-choice survey responses available: 5\n",
      "\n",
      "Education and visualization experience data:\n"
     ]
    }
   ],
   "source": [
    "# Basic demographic information from survey data\n",
    "print(\"\\n2. Basic Demographics\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Get demographic data\n",
    "demo_text = relevant_trials[relevant_trials['trial_type'] == 'survey-text'].copy()\n",
    "demo_multi = relevant_trials[relevant_trials['trial_type'] == 'survey-multi-choice'].copy()\n",
    "\n",
    "if len(demo_text) > 0:\n",
    "    print(\"Text survey responses available:\", len(demo_text))\n",
    "    \n",
    "if len(demo_multi) > 0:\n",
    "    print(\"Multi-choice survey responses available:\", len(demo_multi))\n",
    "    \n",
    "    # Parse responses if they exist\n",
    "    if 'responses' in demo_multi.columns:\n",
    "        print(\"\\nEducation and visualization experience data:\")\n",
    "        for idx, row in demo_multi.iterrows():\n",
    "            if pd.notna(row['responses']):\n",
    "                try:\n",
    "                    responses = json.loads(row['responses'].replace(\"'\", '\"'))\n",
    "                    participant_id = row['participant_id']\n",
    "                    condition = row['condition_id']\n",
    "                    print(f\"  Participant {participant_id} ({condition}): {responses}\")\n",
    "                except:\n",
    "                    print(f\"  Could not parse responses for participant {row['participant_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STUDY SUMMARY OVERVIEW ===\n",
      "Dataset: 92 total rows, 46 columns\n",
      "Participants: 5 unique participants\n",
      "Conditions tested: 5 different conditions\n",
      "\n",
      "Phases:\n",
      "  Phase 1 (no visualization): 5 prediction trials\n",
      "  Phase 2 (with visualization): 5 prediction trials\n",
      "\n",
      "Data collection timeframe:\n",
      "  Earliest: 2025-12-08 04:14:57.200000+00:00\n",
      "  Latest: 2025-12-08 17:26:19.888000+00:00\n",
      "\n",
      "Experimental conditions observed:\n",
      "  condition_7_buggy: Buggy Control (n=1)\n",
      "  condition_0_historical: Historical Only (n=4)\n",
      "  condition_5_pi_hover: PI Plot + Hover (n=1)\n",
      "  condition_9_combined: Combined PI + Ensemble (n=2)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STUDY SUMMARY OVERVIEW ===\")\n",
    "print(f\"Dataset: {combined_data.shape[0]} total rows, {combined_data.shape[1]} columns\")\n",
    "print(f\"Participants: {combined_data['participant_id'].nunique()} unique participants\")\n",
    "print(f\"Conditions tested: {combined_data['condition_id'].nunique()} different conditions\")\n",
    "print(f\"\\nPhases:\")\n",
    "print(f\"  Phase 1 (no visualization): {len(phase1_data)} prediction trials\")\n",
    "print(f\"  Phase 2 (with visualization): {len(phase2_data)} prediction trials\")\n",
    "print(f\"\\nData collection timeframe:\")\n",
    "if 'start_time' in combined_data.columns and combined_data['start_time'].notna().any():\n",
    "    start_times = pd.to_datetime(combined_data['start_time'].dropna())\n",
    "    print(f\"  Earliest: {start_times.min()}\")\n",
    "    print(f\"  Latest: {start_times.max()}\")\n",
    "else:\n",
    "    print(f\"  Timeframe not available in data\")\n",
    "\n",
    "print(f\"\\nExperimental conditions observed:\")\n",
    "unique_conditions = combined_data[['condition_id', 'condition_name']].drop_duplicates().dropna()\n",
    "for _, row in unique_conditions.iterrows():\n",
    "    count = combined_data[combined_data['condition_id'] == row['condition_id']]['participant_id'].nunique()\n",
    "    print(f\"  {row['condition_id']}: {row['condition_name']} (n={count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAVING PROCESSED DATA ===\n",
      "Processed datasets saved:\n",
      "  - processed_phase1_data.csv\n",
      "  - processed_phase2_data.csv\n",
      "  - processed_vis_literacy.csv\n",
      "  - processed_trust_data.csv\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Save processed data for further analysis\n",
    "print(\"\\n=== SAVING PROCESSED DATA ===\")\n",
    "\n",
    "# Save key datasets\n",
    "phase1_data.to_csv('./data/processed_phase1_data.csv', index=False)\n",
    "phase2_data.to_csv('./data/processed_phase2_data.csv', index=False)\n",
    "vis_lit_scores.to_csv('./data/processed_vis_literacy.csv', index=False)\n",
    "trust_data.to_csv('./data/processed_trust_data.csv', index=False)\n",
    "\n",
    "print(\"Processed datasets saved:\")\n",
    "print(\"  - processed_phase1_data.csv\")\n",
    "print(\"  - processed_phase2_data.csv\")\n",
    "print(\"  - processed_vis_literacy.csv\")\n",
    "print(\"  - processed_trust_data.csv\")\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}